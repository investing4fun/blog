{
  
    
        "post0": {
            "title": "Fund performance against index",
            "content": "Fund pricing data I got from inwestinfo.pl website and indicies prices from stooq.pl. . !pip install bs4 pandas fastcore seaborn import datetime import pandas as pd import numpy as np import requests from bs4 import BeautifulSoup import urllib3 urllib3.disable_warnings() # disable ssl verification warnings from fastcore.parallel import parallel from functools import reduce import seaborn as sns . . Getting the data . start_date = datetime.datetime.strptime(&#39;1995-09-01&#39;, &#39;%Y-%m-%d&#39;).date() def dates_since(start_date): d = start_date while d &lt; datetime.date.today(): yield d d += datetime.timedelta(days=1) def get_fund_prices_for_day(day): print(&quot;.&quot;, end=&quot;&quot;) # stock funds from date d url = f&#39;https://www.inwestinfo.pl/fundusze/fundusze-inwestycyjne/wszystkie/?funduszeKategorie%5B%5D=10&amp;archiwum=1&amp;dataArchiwum={day}&#39; res = requests.get(url, verify=False) # do not verify the certificate quotes = [] soup = BeautifulSoup(res.content, &#39;html.parser&#39;) try: table = soup.find(class_=&#39;table-data&#39;) table = table.find(&#39;tbody&#39;) for row in table.find_all(&#39;tr&#39;): cells = row.find_all(&#39;td&#39;) name = cells[2].get_text() date = cells[3].get_text() price = cells[4].get_text() quotes += [(name, date, price)] except: # if parsing doesn&#39;t go as planned (for example no quotes for that day) pass return quotes . . print(&quot;Getting fund pricing data ...&quot;, end=&quot;&quot;) quotes = parallel( # run in parallel to speed it up get_fund_prices_for_day, dates_since(start_date), n_workers=16, progress=False ) quotes = reduce(lambda q1, q2: q1 + q2, quotes) # drop unnecessary dimension df = pd.DataFrame.from_records(quotes, columns=[&#39;name&#39;, &#39;date&#39;, &#39;price&#39;]) df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;]) df[&#39;price&#39;] = df.price.astype(np.double) print(&quot;Done&quot;) . Getting fund pricing data ...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Done . indexes = [&#39;wig&#39;, &#39;wig20&#39;] print(f&quot;Getting pricing data for {&#39;, &#39;.join(indexes)} ... &quot;, end=&quot;&quot;) for index in indexes: df_index = pd.read_csv(f&#39;https://stooq.pl/q/d/l/?s={index}&amp;i=y&#39;, parse_dates=[&#39;Data&#39;]) # get raw data as csv df_index[&#39;name&#39;] = index.upper() df_index = df_index.rename(columns={&#39;Data&#39;:&#39;date&#39;, &#39;Zamkniecie&#39;: &#39;price&#39;})[[&#39;name&#39;, &#39;date&#39;, &#39;price&#39;]] df = df.append(df_index) # append index data to fund pricing data print(&#39;Done&#39;) . Getting pricing data for wig, wig20 ... Done . df[&#39;year&#39;] = df.date.apply(lambda d: d.year) df_fund_year_prices = df.groupby([&#39;name&#39;, &#39;year&#39;]) .apply(lambda gr: gr[gr[&#39;date&#39;] == gr[&#39;date&#39;].max()][&#39;price&#39;]) .reset_index()[[&#39;name&#39;, &#39;year&#39;, &#39;price&#39;]] .drop_duplicates() # get previous price df_fund_year_prices[&#39;price_prev&#39;] = df_fund_year_prices.price.shift(1) df_fund_year_prices[&#39;price_change_pct&#39;] = (df_fund_year_prices[&#39;price&#39;] - df_fund_year_prices[&#39;price_prev&#39;]) / df_fund_year_prices[&#39;price_prev&#39;] * 100 . years_on_market_threshold = 20 # limit to funds that are around long enough df_long_time_on_market = df_fund_year_prices.groupby(&#39;name&#39;).aggregate({&#39;year&#39;:&#39;count&#39;}).rename(columns={&#39;year&#39;:&#39;years_on_market&#39;}) df_long_time_on_market = df_long_time_on_market[df_long_time_on_market.years_on_market &gt; years_on_market_threshold] long_time_on_market_names = df_long_time_on_market.reset_index().name.values . Results . The results look not so bad, but take a look and judge for yourself. The important thing is to takie into consideration compounding and that even small differences in returns early during the investing period produce huge differences for final value of the holdings. . cmap = sns.diverging_palette(h_neg=10, h_pos=134, n=5, center=&#39;light&#39;, as_cmap=True) df_fund_year_prices_old = df_fund_year_prices[ df_fund_year_prices.name.isin(long_time_on_market_names) &amp; (df_fund_year_prices.price_change_pct &lt; 100) &amp; # remove some outliers - fund conversions (df_fund_year_prices.price_change_pct &gt; -70) &amp; # remove some outliers (df_fund_year_prices.year &lt; datetime.date.today().year) # consider only full years ] df_fund_year_prices_old.pivot(index=&#39;year&#39;, columns=&#39;name&#39;, values=&#39;price_change_pct&#39;) .style.background_gradient(cmap=cmap, axis=1) .highlight_null(&#39;white&#39;) . name Esaliens Akcji (d.Legg Mason Akcji) Novo Akcji Pekao Akcji Polskich Santander Akcji Polskich Skarbiec Akcja WIG WIG20 . year . 1992 nan | nan | nan | nan | nan | 13.219454 | 13.201320 | . 1994 nan | nan | nan | nan | nan | -39.922019 | -40.478127 | . 1995 nan | nan | 2.337398 | nan | nan | 1.509414 | 8.183060 | . 1996 nan | nan | 80.834161 | nan | nan | 89.071831 | 82.068443 | . 1997 nan | nan | 4.887424 | nan | nan | 2.267340 | 3.148842 | . 1998 nan | nan | -14.712042 | 9.256845 | nan | -12.765203 | -16.541151 | . 1999 nan | 29.195117 | 34.868017 | 34.486874 | 36.931818 | 41.326706 | 44.102481 | . 2000 -0.547880 | -0.192184 | 0.045517 | 20.674357 | 18.153527 | -1.305050 | 1.542547 | . 2001 -16.295409 | -18.485237 | -16.424022 | -11.323529 | -20.913082 | -21.993994 | -33.468415 | . 2002 7.544830 | 4.527559 | 1.578661 | -14.676617 | 7.504440 | 3.192743 | -2.706192 | . 2003 29.241685 | 31.393597 | 39.067524 | 50.826045 | 44.785213 | 44.919153 | 33.887925 | . 2004 20.470766 | 22.151354 | 19.267823 | 36.404639 | 24.762856 | 27.935024 | 24.556555 | . 2005 24.898889 | 23.942505 | 25.234249 | 40.481814 | 28.548562 | 33.655702 | 35.417251 | . 2006 54.419411 | 38.043170 | 32.327141 | 49.125757 | 40.107618 | 41.602998 | 23.749600 | . 2007 22.104082 | 7.770120 | 6.375512 | 15.490417 | 13.457754 | 10.387846 | 5.191311 | . 2008 -44.134294 | -51.532025 | -58.284457 | -54.939477 | -42.849550 | -51.070379 | -48.214580 | . 2009 31.035677 | 45.302961 | 41.695958 | 55.199307 | 33.623770 | 46.852941 | 33.468177 | . 2010 18.586439 | 10.761724 | 8.744186 | 12.060302 | 8.707598 | 18.766343 | 14.880354 | . 2011 -17.732453 | -21.377876 | -42.999715 | -31.888391 | -23.612468 | -20.834889 | -21.853238 | . 2012 16.911092 | 11.501946 | 15.907954 | 21.836138 | 25.573496 | 26.240283 | 20.447847 | . 2013 12.903413 | -3.336125 | 6.214933 | 1.531072 | 4.732127 | 8.056495 | -7.046125 | . 2014 -3.656471 | 2.811071 | -6.257619 | -2.099349 | -7.651281 | 0.257057 | -3.541887 | . 2015 -8.919488 | -26.588323 | -15.908106 | -9.392933 | -8.187135 | -9.624810 | -19.723741 | . 2016 0.502953 | -0.573980 | 6.082474 | 7.600000 | 10.919017 | 11.377121 | 4.774763 | . 2017 32.246145 | 39.570237 | 17.055394 | 18.370508 | 25.405714 | 23.171471 | 26.350671 | . 2018 -12.980441 | -13.235902 | -14.819427 | -13.007066 | -16.459044 | -9.499704 | -7.499563 | . 2019 4.100827 | -6.997193 | 3.167641 | -1.263538 | -11.333538 | 0.246800 | -5.558215 | . 2020 -9.199757 | -31.370316 | -25.177137 | 1.828154 | 14.510060 | -1.395469 | -7.725723 | . plt = df_fund_year_prices_old.pivot(index=&#39;year&#39;, columns=&#39;name&#39;, values=&#39;price_change_pct&#39;) .plot(figsize=(15,10), ylabel=&quot;% difference from last year&quot;) . TODO: . compounded results and comparison with indexes | test if compounded results are simillar with real fund price at the end | .",
            "url": "https://pawlowskimichal.github.io/blog/ml/investing/2021/01/07/fund-benchmark.html",
            "relUrl": "/ml/investing/2021/01/07/fund-benchmark.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Crypto fundamentals?",
            "content": "I was speculating with BTC last year a bit. I had a good time, but that required daily price monitoring as it is with short term trading on a high volatility instruments. It got me thinking: why I couldn’t relax and treat it more like a long term investment? I believed in bitcoin value! But did I? . After some thinking about it I can’t see any fundamental reason why BTC is growing other then sentiment. Yes, this is very elegant and even beautiful technology, yes I’d like to use it on a daily basis if I could, yes I enjoy that I understand the complexity and the algorithm that governs it. But are those true advantages that could drive it’s value over the long term? . False crypto fundamentals . Let’s debunk some of the “fundamentals” for bitcoin values that I know of: . limitted supply . Surely, Bitcoin in itself is limited in supply. There is a process to create new coins, but around of 80% of all the bitcons have already been mined and there is hard limit embedded in the algorithm. But who is preventing anyone from creating another Bitcoin? Nobody, and this is exactly what is happening - there are hundreds (if not thousands) of crypto currencies, most very simillar to bitcoin, without any real world usage other than speculation mechanism . truely digital money . That is true: the Bitcoin is truly digital, innovative, politically and teritorially independent currency, it doesn’t need any central bank, or any banks as a matter of fact, to exchange money digitally we don’t need intermediaries, we just need good old internet. But this is technicality. Most users already exchange digital money for goods without any problem (with some small cost of each transaction, but they are not aware that they are paying it anyway), they feel safe that someone else protects their money (if your card gets stolen, you are protected from theft, if your bitcoin wallet gets stolen, you’ve basically lost everything) . growing adoption . This is true, it is going mainstream: Revolut, german banks, PayPay are offering or soon will be allowing bitcoin buying and storage. More and more investment banks are onboard as well and increasing theirs bitcoin assets. But what is the true competitive advantage of a bitcoin here? Does adoption is really such a big value that prohibits from swithing to other coin? In my oppinion it is not, at least not in the same way as it is in replacing facebook with other social network where none of your friends are on (making it essentially useless). In case of BTC you can always exchange it back and forth with fiat and other crypto paying exchange and transaction fees. To me bitcoin adoption is like celebrity: famous for being famous. . Other agruments against BTC and most other alt coins . most crypto (and especially bitcoin) mining is resource intensive with a huge carbon footprint and after COVID, environmental disaster is another big problem for our planet, | it fuels gray and dark net. Of course bitcoin is not the root cause of it’s existance, but makes things easier. | . True crypto fundamentals . There is some little value in the adoption of the digital currency (as it costs to exchange to something else), but it is not a big factor as I mentioned before. . One very interesting case stand out for me though: Ethereum (ETH). The ETH value is in being a medium for decentralized finance (DeFi) and a decentralized computational system. So far it was crippled by limited transaction number before v2, but now it soon should be fixed. I shall look into it in the future! . Bitcoin is an ultimate speculative instrument for me. I am not saying I won’t gamble with it once more, but this time I won’t mistake it for investing in fundamentals. .",
            "url": "https://pawlowskimichal.github.io/blog/investing/crypto/2021/01/04/crypto-fundamentals.html",
            "relUrl": "/investing/crypto/2021/01/04/crypto-fundamentals.html",
            "date": " • Jan 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "New Year's resolutions",
            "content": "A lot has happened this year on that front: exercising regularly, restarted my weekly fasting, moved with my learning a bit further… . Another year is a good opportunity to set new goals: . meditate daily | set a long term goal | set aside time for retrospecting and blogging | ad 1. I was starting to mediate quite a few times in my life already, but it never stuck with me. Perhaps this year. This is to have more patience, more focus and more perspective, . ad 2. give a long term goal a shape, so it is something tangible to work towards and it will also help with creating short and mid term goals, . ad 3. for a start 2 hours/week and 1 day/month should be fine. This is to have a bit more structure and planning in my life, to have some time to stop and look back at what was good and what can be better and write down some important learnings. .",
            "url": "https://pawlowskimichal.github.io/blog/personal/spirituality/priority/2021/01/01/new_year_resolutions.html",
            "relUrl": "/personal/spirituality/priority/2021/01/01/new_year_resolutions.html",
            "date": " • Jan 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "What is important for you?",
            "content": "Yesterday we received sad news - our spiritual father Włodzimierz Zatorski OSB has died. After initial shock what shone through were his achievements. He has set up a publishing house, although he had dislexia, he published over 30 books, he helped endless people (including me) to find God. He had a purpose. He had grit. . RIP father! .",
            "url": "https://pawlowskimichal.github.io/blog/priorities/spirituality/2020/12/29/what-is-important-for-you.html",
            "relUrl": "/priorities/spirituality/2020/12/29/what-is-important-for-you.html",
            "date": " • Dec 29, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "WIP Warren Buffet's Ground Rules by Jeremy C. Miller",
            "content": "Who haven’t heared about Warren Buffet? I did, but I didn’t know much about his investment style. He seems to be a very gentle but controversial figure, which in it’s own is pretty rare - either he does something that annoys a lot of people, or he is a wolf in a sheep’s clothing. My working theory is that he’s performance is so good and consistent over the years, that many people in the industry hate him for that. Maybe this book will shed some light on him and his style of investing. Below are the major ideas that I found valuable. . Mr. Market . Buffet’s mentor Ben Graham personifies the market as this bi-polar peron - sometimes maniac, sometimes depressed, but in the long term those periods balance themselves out and intrinsic value of the stock is reflected in price. . Owning a part in the business . Think of owning a stock as of being an owner of that business. Owning a business is not a short term endevour, so you will be less prone to market moods, but put more value in fundamentals of that business. . Quotations - good or bad? . Ability to get a quotation for your stock is surely advatageous. But is it really? … . Compounding . Because of the expotential nature of the interest gains function, it really can shoot up providing we won’t be eating up all the short term profits but reinvest it constantly. With compounding 2 things are crucial: time and interest rate. Even small changes in interest rate can make a huge difference, the same with extending your investments for additional years. . |-|-|-|-| . It is hart to beat the Index . Buffet claims that beating the Index is pretty tough, and most investment managers regurarly fail to do this. He also cautions not to confuse profits with good performance and gives analogy of a duck: It is not duck’s fault when the tide is low, neither there is a reason to quack when the tide is rising. The lesson from this is: always compare your investments in stocks vs. relevant index (benchmark). . Buffet’s believe in difficulty of beating the index made him add to his will that money his wife inherits will be invested in the index fund. . How to invest long term? . Categories of stocks: . Generals (undervalued stocks) | Workouts (arbitrage opportunities like buyout intentions with higher price) | Controls | .",
            "url": "https://pawlowskimichal.github.io/blog/book/investing/2020/12/28/buffets-ground-rules.html",
            "relUrl": "/book/investing/2020/12/28/buffets-ground-rules.html",
            "date": " • Dec 28, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Principles by Ray Dalio",
            "content": "In one of the books I’ve recently read, author recommended to watch Ray Dalio’s How The Economic Machine Works. This is an excellent piece of content that brilliantly explains economy in the layman terms. I thought that this guy is not only an expert, but also an excellent teacher. Later I’ve found out that he is on a missing to pass on his knowledge further and so he is writing book about economy and cycles: Principles by Ray Dalio which is available online free of charge. He is a humble and straightforward man who built the largest hedge fund called Bridgewater. . The video briefly explains concepts like productivity growth, economic cycles, role of the central banks and credit availability as a driver of economic expansion, all in a form of a cartoon. The book is based on numbers going back hundereds of years to show in detail how and why economic cycles are happening to understand that this is inevitable fact for economy. .",
            "url": "https://pawlowskimichal.github.io/blog/book/investing/2020/12/23/principles_ray_dalio.html",
            "relUrl": "/book/investing/2020/12/23/principles_ray_dalio.html",
            "date": " • Dec 23, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Investing - a (re)start",
            "content": "This is the time of the year, when you tend to think of the things to improve in your life. One of the those that kept me busy this year was investing. During the COVID-19 pandemic stock market lured me in one more time. . I became interested in markets right after I turned 18. It was a time of a big boom no the polish stock exchange, and I wanted a piece of it. I didn’t know much about life not to mention how market worked so it was based rather on emotions than on knowledge. Fortunately I didn’ t loose anything, and I didn’t gain much either. This year it started in a similar way - a lot of gut feeling decisions, like buying oil at the rock bottom, buying more BTC etc. Most proved to be profitable, but still it is a gut feeling investing, based on more knowledge than before, but nevertheless emotionally driven. . This year I’ve decided to take more structured approach to investing, that takes less time on a daily basis, is more diversified and in general safer. . This will include: . find out more about different sectors (clean energy, AI/Robotics, healthcare and eldery care, biotech …), | ethical investing, | learn ways automate trading (from basics like stop loss orders, to trading algorithms that can signal certain market conditions, or even perform trades on my behalf), | research Forex, CFDs - is it something I could use to invest and in which circumstances, | figure out best ways to diversity portfolio (funds, ETFs), | how to hedge small, private portfolio, | cutting edge of investing - (like DeFi for example). | build framework for my own, long term investing | . and think of 2021 specific topics: . think about the economic cycle and where we are at now, | prepare calendar with major economic events. | . This is surely not a complete list, but my aim is to research one smallish topic a week + one bigger one a month and write it down for my own benefit. .",
            "url": "https://pawlowskimichal.github.io/blog/priorities/investing/2020/12/22/investing.html",
            "relUrl": "/priorities/investing/2020/12/22/investing.html",
            "date": " • Dec 22, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Loading DICOM images into PyTorch",
            "content": "!pip install imageio . Requirement already satisfied: imageio in /opt/conda/envs/fastai/lib/python3.8/site-packages (2.9.0) Requirement already satisfied: numpy in /opt/conda/envs/fastai/lib/python3.8/site-packages (from imageio) (1.19.1) Requirement already satisfied: pillow in /opt/conda/envs/fastai/lib/python3.8/site-packages (from imageio) (7.2.0) . import imageio import torch . As an example, I&#39;ve downloaded some dicom files from this site . !curl &quot;https://www.visus.com/fileadmin/content/pictures/Downloads/JiveX_DICOME_Viewer/case1.zip&quot; &gt; &quot;case1.zip&quot; !unzip -q case1.zip . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 8449k 100 8449k 0 0 149k 0 0:00:56 0:00:56 --:--:-- 475k . and simply pass the folder to imageio like this: . np_arr = imageio.volread(&#39;case1&#39;) . Reading DICOM (examining files): 1/31 files (3.2%31/31 files (100.0%) Found 1 correct series. Reading DICOM (loading data): 31/31 (100.0%) . turn into torch tensor . As I prefert to work with PyTorch tensors... . dicom_torch = torch.from_numpy(np_arr) . dicom_torch.shape . torch.Size([31, 512, 512]) . ... and this is how it looks like . import matplotlib.pyplot as plt %matplotlib inline . plt.imshow(dicom_torch[10]) . &lt;matplotlib.image.AxesImage at 0x7f3ebe5effd0&gt; .",
            "url": "https://pawlowskimichal.github.io/blog/ml/medical/2020/09/25/loading-dicom.html",
            "relUrl": "/ml/medical/2020/09/25/loading-dicom.html",
            "date": " • Sep 25, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "The building blocks of DL 2",
            "content": "In the previous post I&#39;ve explained what is the most important concept in neural networks - technique that allows us to incrementally find minimum of a function. This is called Gradient Descent algorithm! . In this post I will build on this concept and show you how to create a basic linear model to predict what is on a medical image! . Download data . As in the first post showing how to build medical image recognition with pure statistics, we need to download data first. For some basic description of how the data looks like, see that first post first ;) . ! git clone https://github.com/apolanco3225/Medical-MNIST-Classification.git ! rm -rf ./medical_mnist ! mv Medical-MNIST-Classification/resized/ ./medical_mnist ! rm -rf Medical-MNIST-Classification . Cloning into &#39;Medical-MNIST-Classification&#39;... remote: Enumerating objects: 58532, done. remote: Total 58532 (delta 0), reused 0 (delta 0), pack-reused 58532 Receiving objects: 100% (58532/58532), 77.86 MiB | 17.62 MiB/s, done. Resolving deltas: 100% (506/506), done. Checking connectivity... done. Checking out files: 100% (58959/58959), done. . from pathlib import Path PATH = Path(&quot;medical_mnist/&quot;) . We have much more powerful tools now, so we will deal with all 6 classes now, but first need to prepare data: . all data needs to be numerical | it needs to be in arrays | it needs to be labeled | . classes = [cls.name for cls in PATH.iterdir()] classes . [&#39;AbdomenCT&#39;, &#39;BreastMRI&#39;, &#39;CXR&#39;, &#39;ChestCT&#39;, &#39;Hand&#39;, &#39;HeadCT&#39;] . Prepare data . The plan is to . images = {} for cls in classes: images[cls] = list((PATH/cls).iterdir()) . from PIL import Image . import torch from torchvision.transforms import ToTensor image_tensors = {} for cls in classes: image_tensors[cls] = torch.stack( # converts iterable of tensors into higher dimention single tensor [ ToTensor()( # converts images to tensors Image.open(path) ).view(-1, 64 * 64).squeeze().float()/255 # reshape tensor from 64x64 to vector tensor of size 4096 and convert values for path in (PATH/cls).iterdir()] ) . so let&#39;s see what we got there . for cls in classes: class_shape = image_tensors[cls].shape print(f&quot;{cls} has {class_shape[0]} images of a size {class_shape[1:]}&quot;) . AbdomenCT has 10000 images of a size torch.Size([4096]) BreastMRI has 8954 images of a size torch.Size([4096]) CXR has 10000 images of a size torch.Size([4096]) ChestCT has 10000 images of a size torch.Size([4096]) Hand has 10000 images of a size torch.Size([4096]) HeadCT has 10000 images of a size torch.Size([4096]) . x_train = torch.cat([image_tensors[cls] for cls in classes], dim=0) y_train = torch.cat([torch.tensor([index] * image_tensors[cls].shape[0]) for index, cls in enumerate(classes)]) . shuffle the dataset. This is important as if we don&#39;t do this, images from the classes that we train first will be effectively not as &quot;fresh&quot; in the memmory of the network . permutations = torch.randperm(x_train.shape[0]) . x_train = x_train[permutations] y_train = y_train[permutations] . create validation set that is 20% of the training set - this is important to asses the performance of the model. Validation set doesn&#39;t take part in training, so model is not biased towards those images (it cannot remember those exact images from training). This is essential to see how well model generalizes on examples it has not seen. . valid_pct = 0.2 valid_index = int(x_train.shape[0] * valid_pct) valid_index . 11790 . x_valid = x_train[:valid_index] y_valid = y_train[:valid_index] x_train = x_train[valid_index:] y_train = y_train[valid_index:] . x_train.shape, y_train.shape, x_valid.shape, y_valid.shape . (torch.Size([47164, 4096]), torch.Size([47164]), torch.Size([11790, 4096]), torch.Size([11790])) . Model . Now we need to build the model. Let&#39;s use the most basic building blocks of the neural network - linear layer (linear_layer function) and nonlinearity (softmax function). . def softmax(x): return x - x.exp().sum(-1).unsqueeze(-1) . def linear_layer(x): return x @ weights + bias . the model is a simple function composition (results of linear layer and fed into nonlinear layer (softmax) . def model(x): return softmax(linear_layer(x)) . For the Gradient Descent to work we also need to specify the loss function - this is crucial, as this is the function on which we compute gradients for our parameters. Just a quick recap: Gradient Descent algorithm finds out the values to change function parameters so the function values decreese. . In your case we minimize loss_func. Parameters of this function (passed in a form of preds) are in the model: wegiths and bias. Gradient Descent will give us values to change each of those parameters so we minimize the loss_func . def loss_func(preds, targets): return -preds[range(targets.shape[0]), targets].mean() def accuracy(preds, targets): return (torch.argmax(preds, dim=-1) == targets).float().mean() . And here is the Gradient Descent loop - see comments in the code for details . %%time # number of training examples n = x_train.shape[0] # batch size - this is necessary as we won&#39;t be able to fit all # the examples into the memmory, so we need to do the computations in batches bs = 64 # how many epochs to train for epochs = 15 weights = torch.zeros((64 * 64, 10), requires_grad=True) # define weights matrix bias = torch.zeros(10, requires_grad=True) # and bias term # in each of those epochs algorithm sees all the images. So in this case # we see all the images 15 times for epoch in range(epochs): # here is the loop for batches: in each batch we: # - see 64 images # - compute predictions based on the model # - compute the loss # - compute gradients and update parameters (wegiths and bias) for i in range((n - 1) // bs + 1): # select images for this batch start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] # compute predictions preds = model(xb) # compute loss loss = loss_func(preds, yb) # compute gradients (this is done for us by PyTorch with this backwards function!) loss.backward() # this block is necessary, so computations we do below, are not taken into account when # computing next gradients with torch.no_grad(): # update parameters weights -= weights.grad bias -= bias.grad # zero out the gradients so they are ready for the next batch (otherwise they accumulate values) weights.grad.zero_() bias.grad.zero_() # eventually after each epoch (seeing all the images) we print out how we did print(f&quot;Epoch {epoch} accuracy: {accuracy(model(x_valid),y_valid)}%, loss: {loss_func(model(x_valid), y_valid)}&quot;) . Epoch 0 accuracy: 0.7695504426956177%, loss: 2.5434305667877197 Epoch 1 accuracy: 0.787277340888977%, loss: 2.3623108863830566 Epoch 2 accuracy: 0.7912637591362%, loss: 2.232290267944336 Epoch 3 accuracy: 0.8318066000938416%, loss: 2.134671926498413 Epoch 4 accuracy: 0.9314673542976379%, loss: 2.058687448501587 Epoch 5 accuracy: 0.9561492800712585%, loss: 1.9977604150772095 Epoch 6 accuracy: 0.9601356983184814%, loss: 1.9477065801620483 Epoch 7 accuracy: 0.9603053331375122%, loss: 1.9057585000991821 Epoch 8 accuracy: 0.9602205157279968%, loss: 1.8700224161148071 Epoch 9 accuracy: 0.9598812460899353%, loss: 1.8391577005386353 Epoch 10 accuracy: 0.9594571590423584%, loss: 1.8121910095214844 Epoch 11 accuracy: 0.9597116112709045%, loss: 1.788395881652832 Epoch 12 accuracy: 0.9596267938613892%, loss: 1.7672215700149536 Epoch 13 accuracy: 0.9598812460899353%, loss: 1.7482411861419678 Epoch 14 accuracy: 0.9598812460899353%, loss: 1.7311174869537354 CPU times: user 1min 5s, sys: 173 ms, total: 1min 5s Wall time: 9.22 s . What did we achieve? . With this simplest neural network we got to almost 96% accuracy - this is pretty good. .",
            "url": "https://pawlowskimichal.github.io/blog/ml/medical/2020/07/23/building-blocks-of-dl-linear_model_on_medicalnist.html",
            "relUrl": "/ml/medical/2020/07/23/building-blocks-of-dl-linear_model_on_medicalnist.html",
            "date": " • Jul 23, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "The building blocks of DL 1",
            "content": "Deep learning is so simple that it is hard to believe. Especially with how much magical it seems at first. At it&#39;s core is a piece of code that allows, one step at a time, to be just a bit closer to the solution. You can think of it like the way of finding the top of the mountain: . . Vocabulary: . step - single step of the optimization algorithm that makes parameters of a function just a bit better | gradient - the slope of the loss function, that we want to minimize | learning rate - how fast we adjust parameters based on the gradient | . Task: Find minimum for $f: a x^2 + b$ with Gradient Descent . We have single variable here: $x$. With Gradient Descent we&#39;ll find the value where $f$ is minimal. . In short, gradient descent is an algorithm that walks down the slope - no more no less. . An example function $f$ in python looks like this: . def f(x): return 1.2 * x**2 + 4 . To compute gradient at where we are now, we will use PyTorch magic: . import torch x = torch.tensor(-3.).requires_grad_() . To walk along the function, we will change $x$ by the fraction of the gradient (gradient * learning_rate) . learning_rate = 0.2 . and this is gradient descent algorightm in code: . def step(x, f): # compute y at a given value of x y = f(x) # the backward function of PyTorch tensor computes gradients y.backward() # change value of x in a direction where function decreases # (don&#39;t bother about x.data and x.grad = None - it is just necessary boilerplate) x.data = x - learning_rate * x.grad.data x.grad = None return x . gather x-es and y-s for 10 iterations . xypairs = [] for i in range(10): xypairs.append([x.data, f(x)]) print(f&quot;f({x:.2}) = {f(x):.2}&quot;) x = step(x, f) . f(-3.0) = 1.5e+01 f(-1.6) = 6.9 f(-0.81) = 4.8 f(-0.42) = 4.2 f(-0.22) = 4.1 f(-0.11) = 4.0 f(-0.059) = 4.0 f(-0.031) = 4.0 f(-0.016) = 4.0 f(-0.0083) = 4.0 . &lt;/input&gt; Once Loop Reflect And believe it or not, this is the building block of each the Neural Net - gradient descent algirithm. Stay tuned for the next post where we will use it on a MedicalNist dataset. .",
            "url": "https://pawlowskimichal.github.io/blog/ml/medical/2020/07/20/building-blocks-of-dl-sgd.html",
            "relUrl": "/ml/medical/2020/07/20/building-blocks-of-dl-sgd.html",
            "date": " • Jul 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "MedicalNIST the most basic prediction technique",
            "content": "To start off the blog, I&#39;ve chosen the most basic example I could come up with: . Medical imaging categorization based on comparison between the &quot;statistically average&quot; image from a category and a set of test images. . This will be used to build upon using more advanced techniques, so stay tuned! . But first let&#39;s download the data . ! rm -rf ./medical_mnist ! git clone https://github.com/apolanco3225/Medical-MNIST-Classification.git ! mv Medical-MNIST-Classification/resized/ ./medical_mnist ! rm -rf Medical-MNIST-Classification . Cloning into &#39;Medical-MNIST-Classification&#39;... remote: Enumerating objects: 58532, done. remote: Total 58532 (delta 0), reused 0 (delta 0), pack-reused 58532 Receiving objects: 100% (58532/58532), 77.86 MiB | 4.39 MiB/s, done. Resolving deltas: 100% (506/506), done. Checking connectivity... done. Checking out files: 100% (58959/58959), done. . install useful libraries . # !pip install torch torchvision . data will be downloaded to medical_mnist folder . from pathlib import Path data = Path(&#39;medical_mnist&#39;) list(data.iterdir()) . [PosixPath(&#39;medical_mnist/AbdomenCT&#39;), PosixPath(&#39;medical_mnist/BreastMRI&#39;), PosixPath(&#39;medical_mnist/CXR&#39;), PosixPath(&#39;medical_mnist/ChestCT&#39;), PosixPath(&#39;medical_mnist/Hand&#39;), PosixPath(&#39;medical_mnist/HeadCT&#39;)] . let&#39;s see what we have here... as this is the most basic technique, let&#39;s pick the images that look the most different from each other . import matplotlib.pyplot as plt from PIL import Image for d in data.iterdir(): print(d) plt.imshow(Image.open(list(d.iterdir())[0])) plt.show() . medical_mnist/AbdomenCT . medical_mnist/BreastMRI . medical_mnist/CXR . medical_mnist/ChestCT . medical_mnist/Hand . medical_mnist/HeadCT . load the data into tensors . import torch from torchvision.transforms import ToTensor stacked_cxrs = torch.stack([ToTensor()(Image.open(path)).float()/255 for path in (data/&#39;CXR&#39;).iterdir()]) stacked_heads = torch.stack([ToTensor()(Image.open(path)).float()/255 for path in (data/&#39;HeadCT&#39;).iterdir()]) . as a good practice, let&#39;s look at the first image, so see if we did it correctly . plt.imshow(stacked_cxrs[0][0]) . &lt;matplotlib.image.AxesImage at 0x7f2198995610&gt; . now, let&#39;s build &quot;ideal&quot; image for each of the category. This ideal image is just a mean for each pixel across all the images . mean_cxrs = stacked_cxrs.mean(0) plt.imshow(mean_cxrs[0]) . &lt;matplotlib.image.AxesImage at 0x7f21717d1590&gt; . mean_headct = stacked_heads.mean(0) plt.imshow(mean_headct[0]) . &lt;matplotlib.image.AxesImage at 0x7f211f6b6a50&gt; . now we can see how much example image differs from the ideals: . import torch.nn.functional as F . F.mse_loss(stacked_cxrs[0], mean_cxrs).sqrt() . tensor(0.0010) . F.mse_loss(stacked_cxrs[0], mean_headct).sqrt() . tensor(0.0016) . looks like that one was a CXR indeed - L2 loss between ideal image from CXR category (mean_cxrs) was lower . so let&#39;s build a simple classifier function, that predicts whether image is a headct or not . def is_headct(img_tensor): if F.mse_loss(img_tensor, mean_cxrs) &gt; F.mse_loss(img_tensor, mean_headct): return True else: return False . now we test the classifier . cxrs_preds = torch.tensor([not is_headct(stacked_cxrs[i]) for i in range(stacked_cxrs.shape[0])]) cxrs_accuracy = cxrs_preds.sum().float() / cxrs_preds.shape[0] print(f&#39;Accuracy on CXRs: {round( (cxrs_accuracy).item() * 100, 2)}%&#39;) . Accuracy on CXRs: 99.15% . head_preds = torch.tensor([is_headct(stacked_heads[i]) for i in range(stacked_heads.shape[0])]) head_accuracy = head_preds.sum().float() / head_preds.shape[0] print(f&#39;Accuracy on HeadCTs: {round( (head_accuracy).item() * 100, 2)}%&#39;) . Accuracy on HeadCTs: 100.0% . ... of course: . those classes were the most distinguishable from each other and | we didn&#39;t split into train and test sets here so results are biased (as each image we predict was used to figure out the &quot;ideal&quot; image) | but this was a nice start of this blog :) .",
            "url": "https://pawlowskimichal.github.io/blog/ml/medical/2020/06/19/fist_post.html",
            "relUrl": "/ml/medical/2020/06/19/fist_post.html",
            "date": " • Jun 19, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Husband and father of Weronika. . On a journey to be a better human being. . Software developer turning data scientist. .",
          "url": "https://pawlowskimichal.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pawlowskimichal.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}